{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12073ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T16:52:34.717793Z",
     "start_time": "2023-03-15T16:52:30.867988Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b05d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T04:11:26.034423Z",
     "start_time": "2023-03-14T04:06:32.572941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00cd6312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T04:18:32.343578Z",
     "start_time": "2023-03-14T04:18:32.327095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO, Mr.Smith, how are you doing today? The weather is great and Python is awesome. The sky is pinkish-blue.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example__text = \"HELLO, Mr.Smith, how are you doing today? The weather is great and Python is awesome. The sky is pinkish-blue.\"\n",
    "example__text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65e504c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T04:19:15.114721Z",
     "start_time": "2023-03-14T04:19:15.097975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HELLO, Mr.Smith, how are you doing today?',\n",
       " 'The weather is great and Python is awesome.',\n",
       " 'The sky is pinkish-blue.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.sent_tokenize(example__text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddde165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T04:21:14.850200Z",
     "start_time": "2023-03-14T04:21:14.832517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HELLO',\n",
       " ',',\n",
       " 'Mr.Smith',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " 'today',\n",
       " '?',\n",
       " 'The',\n",
       " 'weather',\n",
       " 'is',\n",
       " 'great',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'is',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'The',\n",
       " 'sky',\n",
       " 'is',\n",
       " 'pinkish-blue',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.word_tokenize(example__text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc8a2a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T14:56:59.797628Z",
     "start_time": "2023-03-14T14:56:59.784620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'example', 'showing', 'stop', 'words', 'filtrarion', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sentence = \"This is an example showing off stop words filtrarion.\"\n",
    "stop_words = set(stopwords.words(\"English\"))\n",
    "\n",
    "# stop_words\n",
    "words = word_tokenize(example_sentence)\n",
    "\n",
    "# filted_sentence = []\n",
    "\n",
    "# for w in words:\n",
    "#     if w not in stop_words:\n",
    "#         filted_sentence.append(w)\n",
    "\n",
    "\n",
    "filted_sentence = [w for w in words if not w in stop_words]\n",
    "filted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb35e674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T16:59:41.893168Z",
     "start_time": "2023-03-15T16:59:41.879660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n",
      "['It', 'is', 'very', 'important', 'to', 'pythonly', 'while', 'you', 'are', 'pythoning', 'with', 'python', '.', 'All', 'pythoners', 'have', 'pythoned', 'poorly', 'at', 'least', 'once', '.']\n",
      "it\n",
      "is\n",
      "veri\n",
      "import\n",
      "to\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"Python\", \"Pythoner\", \"pythoning\", \"pythoned\", \"pythonly\"]\n",
    "\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))\n",
    "\n",
    "new_text = \"It is very important to pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\"\n",
    "words = word_tokenize(new_text)\n",
    "print(words)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd09b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-02T13:33:47.140117Z",
     "start_time": "2023-04-02T13:33:47.135124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a short sentence.', 'This is a longer sentence.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def filter_short_sentences(sentences):\n",
    "    # Use NLTK's sent_tokenize function to split the text into sentences\n",
    "    # Then use a list comprehension to filter out any sentences less than 5 in length\n",
    "    filtered_sentences = [sent for sent in sent_tokenize(sentences) if len(sent) >= 5]\n",
    "    return filtered_sentences\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a short sentence. This is a longer sentence.\"\n",
    "sentences = sent_tokenize(text)\n",
    "# filtered_sentences = filter_short_sentences(sentences)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af103fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
